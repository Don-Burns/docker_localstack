version: '3.7'

x-kafka-defaults:
  &kafka-defaults
  image: confluentinc/cp-server:${KAFKA_VERSION}
  volumes:
    - ./secrets/keystore/broker-1:/etc/kafka/secrets/
    - ./secrets/conf:/etc/kafka/secrets/conf
  depends_on:
    - zookeeper

x-kafka-environment-defaults:
  &kafka-environment-defaults
  KAFKA_ZOOKEEPER_CONNECT: '${KAFKA_ZOOKEEPER_NAME}:2181'
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,SASL_SSL:SASL_SSL,SASL_SSL_HOST:SASL_SSL
  # KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
  # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  # KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
  KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
  KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
  # KAFKA_LOG4J_LOGGERS: "org.apache.zookeeper=ERROR,org.apache.kafka=ERROR,kafka=ERROR,kafka.cluster=ERROR,kafka.controller=ERROR,kafka.coordinator=ERROR,kafka.log=ERROR,kafka.server=ERROR,kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka.controller=WARN,kafka.foo.bar=DEBUG"
  KAFKA_NUM_PARTITIONS: 3
  KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-256
  KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SASL_SSL
  KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-256
  CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_SSL
  CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: SCRAM-SHA-256
  KAFKA_ZOOKEEPER_SASL_ENABLED: "true"
  KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"
  KAFKA_OPTS: -Dzookeeper.sasl.client=true -Dzookeeper.sasl.clientconfig=Client -Djava.security.auth.login.config=/etc/kafka/secrets/conf/kafka_server_jaas.conf
  KAFKA_SSL_KEYSTORE_FILENAME: kafka.broker-1.keystore.jks
  KAFKA_SSL_KEYSTORE_CREDENTIALS: broker-1_keystore_creds
  KAFKA_SSL_KEY_CREDENTIALS: broker-1_sslkey_creds
  KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.broker-1.truststore.jks
  KAFKA_SSL_TRUSTSTORE_CREDENTIALS: broker-1_truststore_creds
  CONFLUENT_METRICS_REPORTER_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/keystore/kafka.broker-1.truststore.jks
  CONFLUENT_METRICS_REPORTER_SSL_TRUSTSTORE_PASSWORD: confluent
  CONFLUENT_METRICS_REPORTER_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/keystore/kafka.broker-1.keystore.jks
  CONFLUENT_METRICS_REPORTER_SSL_KEYSTORE_PASSWORD: confluent
  KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
  KAFKA_SSL_CLIENT_AUTH: requested
  KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS}
  CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: ${CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS}
  KAFKA_OFFSETS_RETENTION_MINUTES: 172800
  KAFKA_SUPER_USERS: ${KAFKA_SUPER_USERS}
  KAFKA_ZOOKEEPER_SET_ACL: "true"
  KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.auth.SimpleAclAuthorizer



services:
  zookeeper-add-kafka-users:
    image: confluentinc/cp-kafka:5.0.1
    container_name: "zookeeper-add-kafka-users"
    depends_on:
      - zookeeper
    command: "bash -c 'echo Waiting for Zookeeper to be ready... && \
                          cub zk-ready zookeeper:2181 120 && \
                          kafka-configs --zookeeper zookeeper:2181 --alter --add-config 'SCRAM-SHA-256=[iterations=4096,password=password]' --entity-type users --entity-name metricsreporter && \
                          kafka-configs --zookeeper zookeeper:2181 --alter --add-config 'SCRAM-SHA-256=[iterations=4096,password=password]' --entity-type users --entity-name kafkaclient && \
                          kafka-configs --zookeeper zookeeper:2181 --alter --add-config 'SCRAM-SHA-256=[iterations=4096,password=password]' --entity-type users --entity-name kafkabroker '"

  zookeeper:
    image: confluentinc/cp-zookeeper:${KAFKA_VERSION}
    hostname: ${KAFKA_ZOOKEEPER_NAME}
    container_name: ${KAFKA_ZOOKEEPER_NAME}
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: -Djava.security.auth.login.config=/etc/kafka/secrets/zookeeper_server_jaas.conf -Dquorum.auth.enableSasl=true -Dquorum.auth.learnerRequireSasl=true -Dquorum.auth.serverRequireSasl=true -Dquorum.cnxn.threads.size=20 -Dzookeeper.authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider -Dzookeeper.authProvider.2=org.apache.zookeeper.server.auth.DigestAuthenticationProvider -DjaasLoginRenew=3600000 -DrequireClientAuthScheme=sasl -Dquorum.auth.learner.loginContext=QuorumLearner -Dquorum.auth.server.loginContext=QuorumServer
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: "DEBUG"
      # ZOOKEEPER_SERVERS: zookeeper:2181:2181
    volumes:
      - ./secrets/conf/zookeeper_server_jaas.conf:/etc/kafka/secrets/zookeeper_server_jaas.conf

  kafka1:
    <<: *kafka-defaults
    hostname: ${KAFKA_CONTAINER_NAME}1
    container_name: ${KAFKA_CONTAINER_NAME}1
    ports:
      - "19092:19092"
    environment:
      <<: *kafka-environment-defaults
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_CONTAINER_NAME}1:9092,PLAINTEXT_HOST://localhost:19092,SASL_SSL://${KAFKA_CONTAINER_NAME}1:9096,SASL_SSL_HOST://localhost:19096
      # PLAINTEXT://${KAFKA_CONTAINER_NAME}1:9092,PLAINTEXT_HOST://localhost:19092, SASL_SSL://${KAFKA_CONTAINER_NAME}1:9096 #,SASL_SSL_HOST://localhost:19096


  # kafka2:
  #   <<: *kafka-defaults
  #   hostname: ${KAFKA_CONTAINER_NAME}2
  #   container_name: ${KAFKA_CONTAINER_NAME}2
  #   ports:
  #     - "29092:29092"
  #   environment:
  #     <<: *kafka-environment-defaults
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_CONTAINER_NAME}2:9092,PLAINTEXT_HOST://localhost:29092


  # kafka3:
  #   <<: *kafka-defaults
  #   hostname: ${KAFKA_CONTAINER_NAME}3
  #   container_name: ${KAFKA_CONTAINER_NAME}3
  #   ports:
  #     - "39092:39092"
  #   environment:
  #     <<: *kafka-environment-defaults
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_CONTAINER_NAME}3:9092,PLAINTEXT_HOST://localhost:39092

  # schema-registry:
  #   image: confluentinc/cp-schema-registry:${KAFKA_VERSION}
  #   hostname: ${KAFKA_SCHEMAREGISTRY_NAME}
  #   container_name: ${KAFKA_SCHEMAREGISTRY_NAME}
  #   depends_on:
  #     - kafka1
  #     - kafka2
  #     - kafka3
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     SCHEMA_REGISTRY_HOST_NAME: ${KAFKA_SCHEMAREGISTRY_NAME}
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: '${KAFKA_CONTAINER_NAME}1:9092,${KAFKA_CONTAINER_NAME}2:9092,${KAFKA_CONTAINER_NAME}3:9092'
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  #     SCHEMA_REGISTRY_DEBUG: 'true'
  #     SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: ${KAFKA_SCHEMAREGISTRY_COMPATIBILITY_LEVEL}

  # schema-registry-ui:
  #   image: landoop/schema-registry-ui:latest
  #   container_name: ${KAFKA_SCHEMAREGISTRYUI_NAME}
  #   depends_on:
  #     - schema-registry
  #   ports:
  #     - "8082:8000"
  #   environment:
  #     SCHEMAREGISTRY_URL: http://${KAFKA_SCHEMAREGISTRY_NAME}:8081
  #     PROXY: 'true'
  #     ALLOW_GLOBAL: 1
  #     ALLOW_TRANSITIVE: 1
  #     ALLOW_DELETION: 1
  #     READONLY_MODE: 1

  # kafdrop:
  #   image: obsidiandynamics/kafdrop:latest
  #   container_name: ${KAFKA_KAFDROP_NAME}
  #   ports:
  #     - "9000:9000"
  #   environment:
  #     KAFKA_BROKERCONNECT: '${KAFKA_CONTAINER_NAME}1:9092,${KAFKA_CONTAINER_NAME}2:9092,${KAFKA_CONTAINER_NAME}3:9092'
  #     JVM_OPTS: '-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify'
  #     CMD_ARGS: '--message.format=AVRO --schemaregistry.connect=http://${KAFKA_SCHEMAREGISTRY_NAME}:8081'
  #   depends_on:
  #     - kafka1
  #     - kafka2
  #     - kafka3
